
GOAL: To come up with a trading strategy using the relationship between FX rates and global stock index prices.

***********
* 1/21/14 *
***********

Worked on model and realized that Matlab is terrible with multiple regression. It has no diagnostic tools especially for multicollinearity and heteroscedasticity. 

*I checked visually for normality, serial correlation and heteroscedasticity and could not see anything.* [fairly confident about this but never know for sure...]

To test of multicollinearity, you can look at the correlation matrix which tells you something, but not everything. Variance inflation factors (VIFs) are more accurate supposedly, and you can use the correlation matrix to calculate VIFs: inv(correlation matrix^Transpose) [I believe] gives you the VIFS for each indep var. A value around 10 or more indicates multicollinearity. All my indep vars results in values that were in their 20s!! So need to confirm this.

To do that I need the matrix of indep vars used in the stepwise reg. How do I create a matrix of said variables? Matlab does not allow you to do that in one step!!

Possible solutions:
(1) Create a database from the equities data
(2) Create individual series of each equity so I can add/drop and create interaction terms if necessary -- this might be more effective, but a lot more work.
(3) ...?

***********
* 1/22/14 *
***********

Starting to split up the data extraction and download files with the regression analysis so I can run repeated regressions without having to keep downloading the data. Need to finish this tomorrow.

Also plan to create an individual series of equity index data so that I can play around with it more. Will do this tomorrow.

***********
* 1/23/14 *
***********

Split up the data extraction and analysis.

Also figured out a way to extract the series of predictors from the entire series of equities. 

Still have to figure out a way to get the interaction variables.

--- LOOKED AT SOMETHING ELSE -----

Today, I looked at the summary stats over the last 5-6 years (2007-13). I looked at:
(1) each individual years as well as
(2A) averages across all the years as well as 
(2B) a subset of the years.

Looking at the data one can see a few things very clearly:

(1) There are clear patterns in the data through the day.
(2) Trades cluster around the hour.
	2A. For years before the crisis (basically 2007) and for years well after the crisis (2012/13), there are patterns within the hour, i.e., the prices start low and increase over the hour.
	2B. For the crisis years, these patterns seem to be there, but not as distinct.
(3) No real consistent patterns across the years in skewness, kurtosis or standard deviation.

IMPORTANT: Based off of DeRosa's "4-pip" (or was it 8 pips?) rule, there seems to be a basic strategy of buying in the morning and selling in the afternoon that *could* potentially lead to a gain of four pips...but very VERY slim! Max daily average range is 4 pips...

---- END OF SOMETHING ELSE ----

Back to the: Still have to figure out a way to get the interaction variables.

Found a way to get all of the regression variables, including the interaction ones. That array has a colon (':') for all interaction variables. 

I am using Matlab's strfind() function to find the ':' in each of the cells to locate the interaction variables. 

I plan to split up the interaction variables based off of the colon, and then use the Time Series object functions to extract the necessary time series and multiply them with each other.

Pick it up again tomorrow...

*************
* 1/24/2014 *
*************

I wrote the code to replicate the results of the stepwise regression and ran a regular multivariate linear regression (using the fitlm() function) to verify that it works. It does!!

Note that though the regression is highly significant and has a large R2, I get significant serial correlation both, by running the dwtest as well as looking at the plot of residuals vs lagged residuals.

Need to deal with that somehow...

Also, I am now exploring ways in which to test multicollinearity in Matlab. It is TERRIBLE with this (may have mentioned this earlier).

---------MULTICOLLINEARITY------------

For multicollinearity, you can:

(1) Calculate RANK: This gives you the number of vectors (columns) that are linearly independent of one another.

rank(predictors) gave me 13 for the 2007 12pm dependent var reg.

(2) Calculate condition number of predictor matrix: The condition number is often used to characterize the overall sensitivity of OLS estimates to changes in the data.

cond(predictors) gave me  1.6478e+10... LARGE! 

This is a problem. 

"The condition number is well above the "well-conditioned" benchmark of 1, which is achieved when  $X_t$ has orthonormal columns. As a rule of thumb, a 1% relative error in the data  $X_t$ can produce up to a  $\kappa$ % relative error in the coefficient estimates  $\beta$ [4]:

$${\|\delta \beta\| \over \|\beta\|} \le \kappa{\|\delta X_t\| \over \|X_t\|}$$

As shown in the previous example on "Linear Models," coefficient estimates for this data are on the order of  $10^{-2}$ , so a  $\kappa$ on the order of  $10^2$ leads to absolute estimation errors  $\|\delta \beta\|$ that are approximated by the relative errors in the data."

(3) You can also calculate the VIFs.

First calculate the correlation matrix of the predictors:
R0 = corrcoef(predictors)

Then, it turns out that "VIFs are also the diagonal elements of the inverse of the correlation matrix [1], a convenient result that eliminates the need to set up the various regressions"

So we can do: VIF = diag(inv(R0))' [on the correlation matrix calculated above] to get our VIFs.

Doing this gives us:

VIF =

   1.0e+04 *

Columns 1 through 10

    0.3898    0.6484    1.1860    0.1723    0.5076    0.1257    0.2816    0.1749    0.2330    0.2491

  Columns 11 through 13

    0.0252    0.4386    0.3434

"How large a VIF is cause for concern? As with significance levels for standard hypothesis tests, experience with certain types of data may suggest useful tolerances. Common ad hoc values, in the range of 5 to 10, are of little use in general."

Furthermore:

"Econometricians have developed a number of rules of thumb for deciding when to worry about collinearity. Perhaps the most common says that it is acceptable to ignore evidence of collinearity if the resulting t-statistics are all greater than 2 in absolute value."

Bottomline? Since the VIFs are all small, and the t-stats are all greater than 2, I am going to ignore the multicollinearity problem.

ADDED ON 2/2:
I had missed the "1.0e+04 *" earlier!! The VIFs are all EXTREMELY large!!

Source: 
http://www.mathworks.com/help/econ/examples/time-series-regression-ii-collinearity-and-estimator-variance.html


----------END MULTICOLLINEARITY--------------

Got sucked into the Matlab pages of examples using the Econometric Toolbox (one of them linked above). It seems that the presence of an omitted variable might inflate the t-stats. This is not something I can worry about right now.

------------BEGIN SPURIOUS REGRESSION-------------------

In addition, if there are positive linear trends in the data, this might result in a SPURIOUS REGRESSION. This is only the case if BOTH dep and indep vars have a positive trend...

"Predictors that trend over time are sometimes viewed with suspicion in multiple linear regression (MLR) models. Individually, however, they need not affect ordinary least squares (OLS) estimation. In particular, there is no need to linearize and detrend each predictor. If response values are well-described by a linear combination of the predictors, an MLR model is still applicable, and classical linear model (CLM) assumptions are not violated.

If, however, a trending predictor is paired with a trending response, there is the possibility of spurious regression, where  $t$ -statistics and overall measures of fit become misleadingly "significant." That is, the statistical significance of relationships in the model do not accurately reflect the causal significance of relationships in the data-generating process (DGP)."

It turns out that on visual inspection, both the prices_endhour AND the predictors do indeed have trends...

GOOD NEWS however, is the the Augmented Dickey Fuller tests on each of the predictors gives 1 [assuming this is reject the null that unit root exists...? need to double-check]

----------------END SPURIOUS REGRESSION---------------

Pick it up again tomorrow.

*************
* 1/25/2014 *
*************

So I double-checked the ADF test and also did another test (the KPSS test) on our predictors from 2007, and they were terrible. All 13 predictors failed both, unit root and stationarity tests.

I then tested for stationarity on first differences and that was better. All first-differenced predictors were free of both unit roots and nonstationarity.

NEXT STEP: Rerun the regression on first-differenced data. Do a stepwise regression on first-differenced equities data.


I also tested for heteroskedasticity using archtest() on the raw residuals and they failed.


I also tested for autocorrelation in the residuals and it is 1 (????!!!!). Need to somehow deal with this as well.

I am going through the Matlab linear regression example and it is very descriptive and describes all the issues and how one can deal with them.

NEXT STEPS:
-----------
Plan to convert the data into a dataset so I don't keep having to adjust it for lags and first-differencing (hopefully). Since you cannot run a regression on a time series object, I plan to convert the TS object to a data set array (DS array).

Once you convert to DS, you can take lags and first-difference away to glory. You can do this on both the dep var and the indep vars.

Also need to go over the CFA stuff on dealing with serial correlation (autocorrelation in the residuals) and figuring out how much to lag the indep vars based off of the autocorrelations of the resids.

At the end of this, I would like a step-by-step process so I can:

(1) Rerun the regression on any subsample of the data 
(2) Go through each of the tests (e.g., unit root, stationarity of indep vars; normality, independence and homoskedasticity of resids, etc.)
(3) Correct for any issues and rerun the regression
(4) Get a reasonable regression which I can use for prediction purposes.

At first, you should correct for autocorrelation in the resids by lagging the indep vars. Instead of taking the first lag, maybe take the 6th or 7th lag (depending on what autocorr() gives you)

QUESTION: Is it worth going through all that hassle? What if I just test my results on the forward data and see how well it predicts...?

I think you should try the latter first, because that is easier and if it works, it works. No need to worry about issues -- you are not trying to get it published; just make money!

More tomorrow/Monday.           


************
* 2/2/2014 *
************

Took a long break from the project (was dealing with CFA stuff)...

Think I have boiled down to two conclusions:
(1) Use 2013 data for your training data and test on January 2014 onwards...
(2) Don't get hung up with the spurious regression stuff. Try predicting forward and see what happens.

Anyway, for now you have not run the basic tests on the 2013 data, so go ahead and do that.

The 2013 data is better with the DW Test on autocorrelation, but there are still concerned about multicollinearity, and co-integration (unit root, stationarity). Not sure what to do at this point, but I'm going to go ahead and see the predictive value of the regression on January 2014 data...

BEFORE I DO THAT: I am going to take the first differences of the predictors (since they all pass the unit root and stationarity test), rerun the regression and see what happens...

---
OOPS!
---
Found a mistake in the input data. I was regressing lagged equity index values against the same-day FX values. I wanted to regress lagged equity index values against next-day FX values (for predictability). Corrected this mistake and results are still pretty good...

Ignore the numbers on regressions run before this (esp on the lagged stuff).

---
END: OOPS!
---

---
FIRST-DIFFERENCING
---

Today I played around with the data a lot. I took first-differences of the lagged equities data and ran a stepwise regression against the FX data. IT DROPPED ALL THE VARIABLES! (Chose only intercept).

Then I took the 2013 EURUSD 11:30am data on the LHS and ran a stepwise on non-D1 data. Next, I differenced it and reran the regression. It lost all of the high t-stats on the predictors, and also the high-R^2, but at least there was no stationarity...

Also got a large, significant, positive alpha. Decided to keep the differenced predictors so that I can use the values in the prediction analysis.

---
END: FIRST-DIFFERENCING
---

I am now starting to work on the prediction analysis part.

Done. For 2014 they are TERRIBLE! (Only 8 dates in Jan that intersect across all time series, and the predictions are NEGATIVE!!)


************
* 2/3/2014 *
************

Played around with the predictions more. The predictive values are coming out very LARGE. What is going on there?

Also, now I need to start playing around with the TWAP as well. Would the TWAP be a better predictor? What about the difference between 11am and TWAP? Need to work on that next...

How about running a regular regression and checking the prediction values on that?



************
* 2/16/2014 *
************

Starting over again with a new paradigm. Since the regression models I have used so far are pretty useless in terms of predictability as well as violating all of the assumptions, I am going take the difference between either the TWAP or two hours so that there is automatically some sort of differencing on the LHS. 

The 10am to 11am TWAP minus 11am prices for 2007 FX values results in something that looks fairly stationary. When I run the regression, it actually leads to reasonable predictions.

Also two tests give normality of residuals (kstest, jbtest). No evidence of autocorrelation or heteroscedasticity.

Wow! Think I might actually have something to present on Thursday!

Tried a number of different alternatives:
(1) 2013 numbers are TERRIBLE. Tried:
	a. 10am to 11am TWAP minus 11am Fix
	b. 9am to 2pm TWAP minus 11am Fix
	c. 11am to 11:30am TWAP minus 11am Fix
	d. 9am to 10am TWAP minus 11am Fix
	e. and more...